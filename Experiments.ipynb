{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c41dea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import time\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51a75436",
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_train = pd.read_csv('pheno_train.csv')\n",
    "pheno_test = pd.read_csv('pheno_test.csv')\n",
    "ss = pd.read_csv('sample_submission.csv')\n",
    "func = h5py.File('abide.hdf5', 'r')\n",
    "\n",
    "# adjust according to submission format\n",
    "pheno_train['DX_GROUP'] = pheno_train['DX_GROUP'] - 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bce4b44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_train(data, pheno, derivative):\n",
    "    X = []\n",
    "    y = []\n",
    "    i = 0\n",
    "    total = pheno.shape[0]\n",
    "    for row in pheno.iterrows():\n",
    "        file_id, dx_group = row[1]['FILE_ID'], row[1]['DX_GROUP']\n",
    "        connectivity = data['patients'][file_id][derivative][()]\n",
    "        X.append(connectivity)\n",
    "        y.append(dx_group)\n",
    "        sys.stdout.write(\"\\r{:.2f}%>\".format(i/total))\n",
    "        sys.stdout.flush()\n",
    "        i += 1\n",
    "        \n",
    "    X = np.array(X).astype(np.float32)\n",
    "    y = np.array(y).astype(np.float32)\n",
    "    return X, y\n",
    "\n",
    "def get_data_test(data, pheno, derivative):\n",
    "    X_test = []\n",
    "    sub_ids = []\n",
    "    j = 0\n",
    "    total = pheno.shape[0]\n",
    "    for row in pheno.iterrows():\n",
    "        file_id, sub_id = row[1]['FILE_ID'], row[1]['SUB_ID']\n",
    "        connectivity = data['patients'][file_id][derivative][()]\n",
    "        X_test.append(connectivity)\n",
    "        sub_ids.append(sub_id)\n",
    "        sys.stdout.write(\"\\r{:.2f}%>\".format(j/total))\n",
    "        sys.stdout.flush()\n",
    "        j += 1\n",
    "        \n",
    "    X_test = np.array(X_test).astype(np.float32)\n",
    "    return X_test, sub_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "603ad1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.00%>"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((931, 6670), (931,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = get_data_train(func, pheno_train, 'aal')\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bda227f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99%>"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((104, 6670), 104)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, sub_ids = get_data_test(func, pheno_test, 'aal')\n",
    "X_test.shape, len(sub_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04b8b4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier as hgbc\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import gc\n",
    "\n",
    "N_SPLITS = 10\n",
    "kf = KFold(n_splits=N_SPLITS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb33fd2f",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf5aec99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0, score: 0.6535326086956522\n",
      "Fold: 1, score: 0.6932573599240266\n",
      "Fold: 2, score: 0.6077705827937097\n",
      "Fold: 3, score: 0.6808905380333952\n",
      "Fold: 4, score: 0.7437258687258688\n",
      "Fold: 5, score: 0.651031894934334\n",
      "Fold: 6, score: 0.7078703703703703\n",
      "Fold: 7, score: 0.7574074074074074\n",
      "Fold: 8, score: 0.6875\n",
      "Fold: 9, score: 0.6796296296296298\n",
      "Mean (std): 0.6862616260514394(0.04174598358018723)\n"
     ]
    }
   ],
   "source": [
    "final_preds = np.zeros((X_test.shape[0], N_SPLITS))\n",
    "i = 0\n",
    "scores = []\n",
    "for tr_idx, val_idx in kf.split(X):\n",
    "    clf = hgbc(max_depth=6, max_leaf_nodes=25, verbose=0, max_iter=30)\n",
    "    clf.fit(X[tr_idx], y[tr_idx])\n",
    "    final_preds[:, i] = clf.predict_proba(X_test)[:, 1]\n",
    "    fold_preds = clf.predict_proba(X[val_idx])[:, 1]\n",
    "    print('Fold: {0}, score: {1}'.format(i, roc_auc_score(y[val_idx], fold_preds)))\n",
    "    scores.append(roc_auc_score(y[val_idx], fold_preds))\n",
    "    del clf\n",
    "    gc.collect()\n",
    "    i += 1\n",
    "print('Mean (std): {0}({1})'.format(np.mean(scores),np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df72466",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d932168",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34b10bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.metrics import *\n",
    "import numpy as np\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af60a83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2ce64f",
   "metadata": {},
   "source": [
    "### Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2dd00233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_Relu():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(6670,1)))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation= 'relu' ))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation= 'sigmoid' ))\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy',Precision(),Recall(),AUC()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bdda7e21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f81da9d3f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold: 0, score: 0.6304347826086956\n",
      "Fold: 1, score: 0.7283950617283951\n",
      "Fold: 2, score: 0.6799259944495838\n",
      "Fold: 3, score: 0.6730055658627085\n",
      "Fold: 4, score: 0.7166988416988417\n",
      "Fold: 5, score: 0.6580675422138837\n",
      "Fold: 6, score: 0.9046296296296297\n",
      "Fold: 7, score: 0.7513888888888889\n",
      "Fold: 8, score: 0.6828703703703703\n",
      "Fold: 9, score: 0.6671296296296297\n",
      "Mean (std): 0.7092546307080626(0.07337980191596208)\n"
     ]
    }
   ],
   "source": [
    "final_preds = np.zeros((X_test.shape[0], N_SPLITS))\n",
    "i = 0\n",
    "scores = []\n",
    "epochs,batch_size,verbose=20,10,False\n",
    "for tr_idx, val_idx in kf.split(X):\n",
    "    model = cnn_Relu()\n",
    "    mean = X[tr_idx].mean(axis=0)\n",
    "    std = X[tr_idx].std(axis=0)\n",
    "    X_train =  X[tr_idx]\n",
    "    X_val = X[val_idx] \n",
    "    \n",
    "    model.fit(np.reshape(X_train,(X[tr_idx].shape[0],X[tr_idx].shape[1],1)),\n",
    "                         y[tr_idx], epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    final_preds[:, i] = model.predict_proba(np.reshape(X_test,(X_test.shape[0],6670,1)))[:, 0]\n",
    "    fold_preds = model.predict_proba(np.reshape(X_val,(X[val_idx].shape[0],6670,1)))[:, 0]\n",
    "    print('Fold: {0}, score: {1}'.format(i, roc_auc_score(y[val_idx], fold_preds)))\n",
    "    scores.append(roc_auc_score(y[val_idx], fold_preds))\n",
    "    del model\n",
    "    gc.collect()\n",
    "    i += 1\n",
    "print('Mean (std): {0}({1})'.format(np.mean(scores),np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db7b5160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_Relu_v2():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(6670,1)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation= 'relu' ))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation= 'sigmoid' ))\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy',Precision(),Recall(),AUC()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c4c25ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0, score: 0.5797101449275363\n",
      "Fold: 1, score: 0.6937321937321937\n",
      "Fold: 2, score: 0.6285846438482887\n",
      "Fold: 3, score: 0.6804267161410018\n",
      "Fold: 4, score: 0.7282818532818532\n",
      "Fold: 5, score: 0.6796435272045028\n",
      "Fold: 6, score: 0.7625\n",
      "Fold: 7, score: 0.7474537037037037\n",
      "Fold: 8, score: 0.6331018518518519\n",
      "Fold: 9, score: 0.6893518518518518\n",
      "Mean (std): 0.6822786486542783(0.053677590033873686)\n"
     ]
    }
   ],
   "source": [
    "final_preds = np.zeros((X_test.shape[0], N_SPLITS))\n",
    "i = 0\n",
    "scores = []\n",
    "epochs,batch_size,verbose=50,10,False\n",
    "for tr_idx, val_idx in kf.split(X):\n",
    "    model = cnn_Relu_v2()\n",
    "    mean = X[tr_idx].mean(axis=0)\n",
    "    std = X[tr_idx].std(axis=0)\n",
    "    X_train =  X[tr_idx]\n",
    "    X_val = X[val_idx] \n",
    "    \n",
    "    model.fit(np.reshape(X_train,(X[tr_idx].shape[0],X[tr_idx].shape[1],1)),\n",
    "                         y[tr_idx], epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    final_preds[:, i] = model.predict_proba(np.reshape(X_test,(X_test.shape[0],6670,1)))[:, 0]\n",
    "    fold_preds = model.predict_proba(np.reshape(X_val,(X[val_idx].shape[0],6670,1)))[:, 0]\n",
    "    print('Fold: {0}, score: {1}'.format(i, roc_auc_score(y[val_idx], fold_preds)))\n",
    "    scores.append(roc_auc_score(y[val_idx], fold_preds))\n",
    "    del model\n",
    "    gc.collect()\n",
    "    i += 1\n",
    "print('Mean (std): {0}({1})'.format(np.mean(scores),np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "18780e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_Relu_v3():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(6670,1)))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation= 'relu' ))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(50, activation= 'relu' ))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation= 'sigmoid' ))\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy',Precision(),Recall(),AUC()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bdf76a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0, score: 0.5892210144927537\n",
      "Fold: 1, score: 0.7559354226020893\n",
      "Fold: 2, score: 0.7354301572617946\n",
      "Fold: 3, score: 0.6739332096474954\n",
      "Fold: 4, score: 0.7104247104247104\n",
      "Fold: 5, score: 0.6130393996247655\n",
      "Fold: 6, score: 0.8078703703703703\n",
      "Fold: 7, score: 0.6916666666666667\n",
      "Fold: 8, score: 0.6224537037037037\n",
      "Fold: 9, score: 0.6884259259259259\n",
      "Mean (std): 0.6888400580720275(0.06450872406853164)\n"
     ]
    }
   ],
   "source": [
    "final_preds = np.zeros((X_test.shape[0], N_SPLITS))\n",
    "i = 0\n",
    "scores = []\n",
    "epochs,batch_size,verbose=20,10,False\n",
    "for tr_idx, val_idx in kf.split(X):\n",
    "    model = cnn_Relu_v3()\n",
    "    mean = X[tr_idx].mean(axis=0)\n",
    "    std = X[tr_idx].std(axis=0)\n",
    "    X_train =  X[tr_idx]\n",
    "    X_val = X[val_idx] \n",
    "    \n",
    "    model.fit(np.reshape(X_train,(X[tr_idx].shape[0],X[tr_idx].shape[1],1)),\n",
    "                         y[tr_idx], epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    final_preds[:, i] = model.predict_proba(np.reshape(X_test,(X_test.shape[0],6670,1)))[:, 0]\n",
    "    fold_preds = model.predict_proba(np.reshape(X_val,(X[val_idx].shape[0],6670,1)))[:, 0]\n",
    "    print('Fold: {0}, score: {1}'.format(i, roc_auc_score(y[val_idx], fold_preds)))\n",
    "    scores.append(roc_auc_score(y[val_idx], fold_preds))\n",
    "    del model\n",
    "    gc.collect()\n",
    "    i += 1\n",
    "print('Mean (std): {0}({1})'.format(np.mean(scores),np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9177a732",
   "metadata": {},
   "source": [
    "### Relu-Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6dcb1614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0, score: 0.6186594202898551\n",
      "Fold: 1, score: 0.7274453941120609\n",
      "Fold: 2, score: 0.7183163737280296\n",
      "Fold: 3, score: 0.7124304267161411\n",
      "Fold: 4, score: 0.7591698841698842\n",
      "Fold: 5, score: 0.6604127579737336\n",
      "Fold: 6, score: 0.8449074074074074\n",
      "Fold: 7, score: 0.700462962962963\n",
      "Fold: 8, score: 0.6453703703703703\n",
      "Fold: 9, score: 0.6856481481481481\n",
      "Mean (std): 0.7072823145878594(0.06048652050505688)\n"
     ]
    }
   ],
   "source": [
    "final_preds = np.zeros((X_test.shape[0], N_SPLITS))\n",
    "i = 0\n",
    "scores = []\n",
    "epochs,batch_size,verbose=20,10,False\n",
    "for tr_idx, val_idx in kf.split(X):\n",
    "    model = cnn_Relu()\n",
    "    mean = X[tr_idx].mean(axis=0)\n",
    "    std = X[tr_idx].std(axis=0)\n",
    "    X_train =  X[tr_idx] - mean\n",
    "    X_train /= std\n",
    "    X_val = X[val_idx] - mean\n",
    "    X_val /= std\n",
    "    X_test -= mean\n",
    "    X_test /=std\n",
    "    \n",
    "    model.fit(np.reshape(X_train,(X[tr_idx].shape[0],X[tr_idx].shape[1],1)),\n",
    "                         y[tr_idx], epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    final_preds[:, i] = model.predict_proba(np.reshape(X_test,(X_test.shape[0],6670,1)))[:, 0]\n",
    "    fold_preds = model.predict_proba(np.reshape(X_val,(X[val_idx].shape[0],6670,1)))[:, 0]\n",
    "    print('Fold: {0}, score: {1}'.format(i, roc_auc_score(y[val_idx], fold_preds)))\n",
    "    scores.append(roc_auc_score(y[val_idx], fold_preds))\n",
    "    del model\n",
    "    gc.collect()\n",
    "    i += 1\n",
    "print('Mean (std): {0}({1})'.format(np.mean(scores),np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3549f30",
   "metadata": {},
   "source": [
    "### Relu-Normalization-L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05fa4e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_relu_l2():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(6670,1),kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation= 'relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01) ))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation= 'sigmoid',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01) ))\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy',Precision(),Recall(),AUC()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51235ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0, score: 0.5801630434782609\n",
      "Fold: 1, score: 0.7378917378917378\n",
      "Fold: 2, score: 0.6623496762257168\n",
      "Fold: 3, score: 0.6600185528756957\n",
      "Fold: 4, score: 0.790057915057915\n",
      "Fold: 5, score: 0.7176360225140713\n",
      "Fold: 6, score: 0.7666666666666667\n",
      "Fold: 7, score: 0.7032407407407407\n",
      "Fold: 8, score: 0.6773148148148148\n",
      "Fold: 9, score: 0.65\n",
      "Mean (std): 0.694533917026562(0.05865576198393549)\n"
     ]
    }
   ],
   "source": [
    "final_preds = np.zeros((X_test.shape[0], N_SPLITS))\n",
    "i = 0\n",
    "scores = []\n",
    "epochs,batch_size,verbose=20,10,False\n",
    "for tr_idx, val_idx in kf.split(X):\n",
    "    model = cnn_relu_l2()\n",
    "    mean = X[tr_idx].mean(axis=0)\n",
    "    std = X[tr_idx].std(axis=0)\n",
    "    X_train =  X[tr_idx] - mean\n",
    "    X_train /= std\n",
    "    X_val = X[val_idx] - mean\n",
    "    X_val /= std\n",
    "    X_test -= mean\n",
    "    X_test /=std\n",
    "    \n",
    "    model.fit(np.reshape(X_train,(X[tr_idx].shape[0],X[tr_idx].shape[1],1)),\n",
    "                         y[tr_idx], epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    final_preds[:, i] = model.predict_proba(np.reshape(X_test,(X_test.shape[0],6670,1)))[:, 0]\n",
    "    fold_preds = model.predict_proba(np.reshape(X_val,(X[val_idx].shape[0],6670,1)))[:, 0]\n",
    "    print('Fold: {0}, score: {1}'.format(i, roc_auc_score(y[val_idx], fold_preds)))\n",
    "    scores.append(roc_auc_score(y[val_idx], fold_preds))\n",
    "    del model\n",
    "    gc.collect()\n",
    "    i += 1\n",
    "print('Mean (std): {0}({1})'.format(np.mean(scores),np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb60baf2",
   "metadata": {},
   "source": [
    "### LeakyRelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6a656fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0, score: 0.6521739130434782\n",
      "Fold: 1, score: 0.7711301044634378\n",
      "Fold: 2, score: 0.6981961147086032\n",
      "Fold: 3, score: 0.6892393320964749\n",
      "Fold: 4, score: 0.7799227799227799\n",
      "Fold: 5, score: 0.6362570356472796\n",
      "Fold: 6, score: 0.8358796296296296\n",
      "Fold: 7, score: 0.7212962962962963\n",
      "Fold: 8, score: 0.6206018518518518\n",
      "Fold: 9, score: 0.6578703703703703\n",
      "Mean (std): 0.7062567428030201(0.06672405704598806)\n"
     ]
    }
   ],
   "source": [
    "final_preds = np.zeros((X_test.shape[0], N_SPLITS))\n",
    "i = 0\n",
    "scores = []\n",
    "epochs,batch_size,verbose=20,10,False\n",
    "for tr_idx, val_idx in kf.split(X):\n",
    "    model = cnn_LeakyRelu_Normalization()\n",
    "    mean = X[tr_idx].mean(axis=0)\n",
    "    std = X[tr_idx].std(axis=0)\n",
    "    X_train =  X[tr_idx]\n",
    "    X_val = X[val_idx] \n",
    "    \n",
    "    model.fit(np.reshape(X_train,(X[tr_idx].shape[0],X[tr_idx].shape[1],1)),\n",
    "                         y[tr_idx], epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    final_preds[:, i] = model.predict_proba(np.reshape(X_test,(X_test.shape[0],6670,1)))[:, 0]\n",
    "    fold_preds = model.predict_proba(np.reshape(X_val,(X[val_idx].shape[0],6670,1)))[:, 0]\n",
    "    print('Fold: {0}, score: {1}'.format(i, roc_auc_score(y[val_idx], fold_preds)))\n",
    "    scores.append(roc_auc_score(y[val_idx], fold_preds))\n",
    "    del model\n",
    "    gc.collect()\n",
    "    i += 1\n",
    "print('Mean (std): {0}({1})'.format(np.mean(scores),np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e77c98",
   "metadata": {},
   "source": [
    "### CNN-LeakyRelu-Normalization-L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f1a25b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_LeakyRelu_Normalization_L2():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, input_shape=(6670,1),kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Conv1D(filters=64, kernel_size=3,kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100,kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation= 'sigmoid',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01) ))\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=[AUC()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1936f5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0, score: 0.5339673913043478\n",
      "Fold: 1, score: 0.6894586894586894\n",
      "Fold: 2, score: 0.6655874190564293\n",
      "Fold: 3, score: 0.6632653061224489\n",
      "Fold: 4, score: 0.7842664092664093\n",
      "Fold: 5, score: 0.7265478424015009\n",
      "Fold: 6, score: 0.8027777777777778\n",
      "Fold: 7, score: 0.7356481481481482\n",
      "Fold: 8, score: 0.6657407407407409\n",
      "Fold: 9, score: 0.6189814814814815\n",
      "Mean (std): 0.6886241205757974(0.07502991299410879)\n"
     ]
    }
   ],
   "source": [
    "final_preds = np.zeros((X_test.shape[0], N_SPLITS))\n",
    "i = 0\n",
    "scores = []\n",
    "epochs,batch_size,verbose=30,10,False\n",
    "for tr_idx, val_idx in kf.split(X):\n",
    "    model = cnn_LeakyRelu_Normalization_L2()\n",
    "    mean = X[tr_idx].mean(axis=0)\n",
    "    std = X[tr_idx].std(axis=0)\n",
    "    X_train =  X[tr_idx] - mean\n",
    "    X_train /= std\n",
    "    X_val = X[val_idx] - mean\n",
    "    X_val /= std\n",
    "    X_test -= mean\n",
    "    X_test /=std\n",
    "    \n",
    "    model.fit(np.reshape(X_train,(X[tr_idx].shape[0],X[tr_idx].shape[1],1)),\n",
    "                         y[tr_idx], epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    final_preds[:, i] = model.predict_proba(np.reshape(X_test,(X_test.shape[0],6670,1)))[:, 0]\n",
    "    fold_preds = model.predict_proba(np.reshape(X_val,(X[val_idx].shape[0],6670,1)))[:, 0]\n",
    "    print('Fold: {0}, score: {1}'.format(i, roc_auc_score(y[val_idx], fold_preds)))\n",
    "    scores.append(roc_auc_score(y[val_idx], fold_preds))\n",
    "    del model\n",
    "    gc.collect()\n",
    "    i += 1\n",
    "print('Mean (std): {0}({1})'.format(np.mean(scores),np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3cd590",
   "metadata": {},
   "source": [
    "### CNN-LeakyRelu-Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4aa65081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_LeakyRelu_Normalization():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, input_shape=(6670,1)))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Conv1D(filters=64, kernel_size=3))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100))\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation= 'sigmoid' ))\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=[AUC()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "51afe2c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0, score: 0.6478713768115942\n",
      "Fold: 1, score: 0.7207977207977208\n",
      "Fold: 2, score: 0.6947271045328399\n",
      "Fold: 3, score: 0.7147495361781077\n",
      "Fold: 4, score: 0.7569980694980695\n",
      "Fold: 5, score: 0.7030956848030019\n",
      "Fold: 6, score: 0.8439814814814814\n",
      "Fold: 7, score: 0.7157407407407408\n",
      "Fold: 8, score: 0.6398148148148148\n",
      "Fold: 9, score: 0.6243055555555556\n",
      "Mean (std): 0.7062082085213927(0.06049675926413624)\n"
     ]
    }
   ],
   "source": [
    "final_preds = np.zeros((X_test.shape[0], N_SPLITS))\n",
    "i = 0\n",
    "scores = []\n",
    "epochs,batch_size,verbose=20,10,False\n",
    "for tr_idx, val_idx in kf.split(X):\n",
    "    model = cnn_LeakyRelu_Normalization()\n",
    "    mean = X[tr_idx].mean(axis=0)\n",
    "    std = X[tr_idx].std(axis=0)\n",
    "    X_train =  X[tr_idx] - mean\n",
    "    X_train /= std\n",
    "    X_val = X[val_idx] - mean\n",
    "    X_val /= std\n",
    "    X_test -= mean\n",
    "    X_test /=std\n",
    "    \n",
    "    model.fit(np.reshape(X_train,(X[tr_idx].shape[0],X[tr_idx].shape[1],1)),\n",
    "                         y[tr_idx], epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    final_preds[:, i] = model.predict_proba(np.reshape(X_test,(X_test.shape[0],6670,1)))[:, 0]\n",
    "    fold_preds = model.predict_proba(np.reshape(X_val,(X[val_idx].shape[0],6670,1)))[:, 0]\n",
    "    print('Fold: {0}, score: {1}'.format(i, roc_auc_score(y[val_idx], fold_preds)))\n",
    "    scores.append(roc_auc_score(y[val_idx], fold_preds))\n",
    "    del model\n",
    "    gc.collect()\n",
    "    i += 1\n",
    "print('Mean (std): {0}({1})'.format(np.mean(scores),np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c7b14d",
   "metadata": {},
   "source": [
    "### SeLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5db3eba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_Selu():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='selu', input_shape=(6670,1)))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='selu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation= 'selu' ))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation= 'sigmoid' ))\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy',Precision(),Recall(),AUC()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e1c2bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0, score: 0.6759510869565218\n",
      "Fold: 1, score: 0.6844729344729346\n",
      "Fold: 2, score: 0.7583256244218316\n",
      "Fold: 3, score: 0.6713821892393321\n",
      "Fold: 4, score: 0.7567567567567569\n",
      "Fold: 5, score: 0.6550187617260788\n",
      "Fold: 6, score: 0.7972222222222223\n",
      "Fold: 7, score: 0.7106481481481481\n",
      "Fold: 8, score: 0.6243055555555556\n",
      "Fold: 9, score: 0.6479166666666667\n",
      "Mean (std): 0.6981999946166049(0.05316051604664803)\n"
     ]
    }
   ],
   "source": [
    "final_preds = np.zeros((X_test.shape[0], N_SPLITS))\n",
    "i = 0\n",
    "scores = []\n",
    "epochs,batch_size,verbose=20,10,False\n",
    "for tr_idx, val_idx in kf.split(X):\n",
    "    model = cnn_Selu()\n",
    "    mean = X[tr_idx].mean(axis=0)\n",
    "    std = X[tr_idx].std(axis=0)\n",
    "    X_train =  X[tr_idx]\n",
    "    X_val = X[val_idx] \n",
    "    \n",
    "    model.fit(np.reshape(X_train,(X[tr_idx].shape[0],X[tr_idx].shape[1],1)),\n",
    "                         y[tr_idx], epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    final_preds[:, i] = model.predict_proba(np.reshape(X_test,(X_test.shape[0],6670,1)))[:, 0]\n",
    "    fold_preds = model.predict_proba(np.reshape(X_val,(X[val_idx].shape[0],6670,1)))[:, 0]\n",
    "    print('Fold: {0}, score: {1}'.format(i, roc_auc_score(y[val_idx], fold_preds)))\n",
    "    scores.append(roc_auc_score(y[val_idx], fold_preds))\n",
    "    del model\n",
    "    gc.collect()\n",
    "    i += 1\n",
    "print('Mean (std): {0}({1})'.format(np.mean(scores),np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38b84d1",
   "metadata": {},
   "source": [
    "### Selu-Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "823b0c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0, score: 0.6096014492753623\n",
      "Fold: 1, score: 0.5788224121557455\n",
      "Fold: 2, score: 0.635522664199815\n",
      "Fold: 3, score: 0.6240723562152133\n",
      "Fold: 4, score: 0.7236969111969113\n",
      "Fold: 5, score: 0.6053001876172608\n",
      "Fold: 6, score: 0.8222222222222222\n",
      "Fold: 7, score: 0.7074074074074073\n",
      "Fold: 8, score: 0.6131944444444445\n",
      "Fold: 9, score: 0.6655092592592593\n",
      "Mean (std): 0.6585349313993641(0.06988009414568881)\n"
     ]
    }
   ],
   "source": [
    "final_preds = np.zeros((X_test.shape[0], N_SPLITS))\n",
    "i = 0\n",
    "scores = []\n",
    "epochs,batch_size,verbose=20,10,False\n",
    "for tr_idx, val_idx in kf.split(X):\n",
    "    model = cnn_Selu()\n",
    "    mean = X[tr_idx].mean(axis=0)\n",
    "    std = X[tr_idx].std(axis=0)\n",
    "    X_train =  X[tr_idx] - mean\n",
    "    X_train /= std\n",
    "    X_val = X[val_idx] - mean\n",
    "    X_val /= std\n",
    "    X_test -= mean\n",
    "    X_test /=std\n",
    "    \n",
    "    model.fit(np.reshape(X_train,(X[tr_idx].shape[0],X[tr_idx].shape[1],1)),\n",
    "                         y[tr_idx], epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    final_preds[:, i] = model.predict_proba(np.reshape(X_test,(X_test.shape[0],6670,1)))[:, 0]\n",
    "    fold_preds = model.predict_proba(np.reshape(X_val,(X[val_idx].shape[0],6670,1)))[:, 0]\n",
    "    print('Fold: {0}, score: {1}'.format(i, roc_auc_score(y[val_idx], fold_preds)))\n",
    "    scores.append(roc_auc_score(y[val_idx], fold_preds))\n",
    "    del model\n",
    "    gc.collect()\n",
    "    i += 1\n",
    "print('Mean (std): {0}({1})'.format(np.mean(scores),np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4964e4",
   "metadata": {},
   "source": [
    "### Selu-Normalization-L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f6b45dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_selu_l2():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='selu', input_shape=(6670,1),kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='selu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation= 'selu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01) ))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation= 'sigmoid',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01) ))\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy',Precision(),Recall(),AUC()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "439ecb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0, score: 0.6277173913043479\n",
      "Fold: 1, score: 0.6509971509971509\n",
      "Fold: 2, score: 0.66049953746531\n",
      "Fold: 3, score: 0.7077922077922079\n",
      "Fold: 4, score: 0.7562741312741313\n",
      "Fold: 5, score: 0.6186679174484052\n",
      "Fold: 6, score: 0.7685185185185185\n",
      "Fold: 7, score: 0.7388888888888889\n",
      "Fold: 8, score: 0.6504629629629631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathan/.virtualenvs/tensorflow2/lib/python3.6/site-packages/ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 9, score: 0.6560185185185186\n",
      "Mean (std): 0.6835837225170442(0.05189337667037995)\n"
     ]
    }
   ],
   "source": [
    "final_preds = np.zeros((X_test.shape[0], N_SPLITS))\n",
    "i = 0\n",
    "scores = []\n",
    "epochs,batch_size,verbose=20,10,False\n",
    "for tr_idx, val_idx in kf.split(X):\n",
    "    model = cnn_selu_l2()\n",
    "    mean = X[tr_idx].mean(axis=0)\n",
    "    std = X[tr_idx].std(axis=0)\n",
    "    X_train =  X[tr_idx] - mean\n",
    "    X_train /= std\n",
    "    X_val = X[val_idx] - mean\n",
    "    X_val /= std\n",
    "    X_test -= mean\n",
    "    X_test /=std\n",
    "    \n",
    "    model.fit(np.reshape(X_train,(X[tr_idx].shape[0],X[tr_idx].shape[1],1)),\n",
    "                         y[tr_idx], epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    final_preds[:, i] = model.predict_proba(np.reshape(X_test,(X_test.shape[0],6670,1)))[:, 0]\n",
    "    fold_preds = model.predict_proba(np.reshape(X_val,(X[val_idx].shape[0],6670,1)))[:, 0]\n",
    "    print('Fold: {0}, score: {1}'.format(i, roc_auc_score(y[val_idx], fold_preds)))\n",
    "    scores.append(roc_auc_score(y[val_idx], fold_preds))\n",
    "    del model\n",
    "    gc.collect()\n",
    "    i += 1\n",
    "print('Mean (std): {0}({1})'.format(np.mean(scores),np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b807da2",
   "metadata": {},
   "source": [
    "## CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8f40d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.metrics import *\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2459e5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fcc2459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_lstm():\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "    input_shape=(None,667,1)))\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu')))\n",
    "    model.add(TimeDistributed(Dropout(0.5)))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation= 'sigmoid' ))\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy',Precision(),Recall(),AUC()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2603fb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-87f242a995a7>:15: Sequential.predict_proba (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use `model.predict()` instead.\n",
      "Fold: 0, score: 0.6567028985507246\n",
      "Fold: 1, score: 0.6828110161443495\n",
      "Fold: 2, score: 0.6119333950046253\n",
      "Fold: 3, score: 0.7430426716141002\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f81e9562378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold: 4, score: 0.6655405405405407\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f81e9409268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold: 5, score: 0.6918386491557224\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f81e97d3d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold: 6, score: 0.7856481481481481\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f81e97bfb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold: 7, score: 0.7124999999999999\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f81e99e6950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold: 8, score: 0.6856481481481481\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f81e9a70730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold: 9, score: 0.6476851851851851\n",
      "Mean (std): 0.6883350652491544(0.047017575866168324)\n"
     ]
    }
   ],
   "source": [
    "final_preds = np.zeros((X_test.shape[0], N_SPLITS))\n",
    "i = 0\n",
    "scores = []\n",
    "epochs,batch_size,verbose=50,128,0\n",
    "for tr_idx, val_idx in kf.split(X):\n",
    "    model = cnn_lstm()\n",
    "    mean = X[tr_idx].mean(axis=0)\n",
    "    std = X[tr_idx].std(axis=0)\n",
    "    X_train =  X[tr_idx]\n",
    "    X_val = X[val_idx] \n",
    "    X_train = X_train.reshape((X_train.shape[0], 10, 667, 1))\n",
    "    X_val = X_val.reshape((X_val.shape[0], 10, 667, 1))\n",
    "    model.fit(X_train,y[tr_idx], epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    #final_preds[:, i] = model.predict_proba(np.reshape(X_test,(X_test.shape[0],6670,1)))[:, 0]\n",
    "    fold_preds = model.predict_proba(X_val)[:, 0]\n",
    "    print('Fold: {0}, score: {1}'.format(i, roc_auc_score(y[val_idx], fold_preds)))\n",
    "    scores.append(roc_auc_score(y[val_idx], fold_preds))\n",
    "    del model\n",
    "    gc.collect()\n",
    "    i += 1\n",
    "print('Mean (std): {0}({1})'.format(np.mean(scores),np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e69131",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74ecb483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f81e8eb3598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold: 0, score: 0.49501811594202894\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f81e8c98268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold: 1, score: 0.6918328584995251\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f81e8c55c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold: 2, score: 0.6253469010175763\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f81e8c46ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold: 3, score: 0.549165120593692\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f81e8c36c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold: 4, score: 0.7002895752895753\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f81e8d1fa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold: 5, score: 0.6163227016885552\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f81e8cffd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold: 6, score: 0.6763888888888889\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f81e9a67ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold: 7, score: 0.7467592592592593\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f81e3e158c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold: 8, score: 0.6597222222222222\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f81e3e3f6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold: 9, score: 0.6143518518518519\n",
      "Mean (std): 0.6375197495253175(0.07076333492459112)\n"
     ]
    }
   ],
   "source": [
    "final_preds = np.zeros((X_test.shape[0], N_SPLITS))\n",
    "i = 0\n",
    "scores = []\n",
    "epochs,batch_size,verbose=50,128,0\n",
    "for tr_idx, val_idx in kf.split(X):\n",
    "    model = cnn_lstm()\n",
    "    mean = X[tr_idx].mean(axis=0)\n",
    "    std = X[tr_idx].std(axis=0)\n",
    "    X_train =  X[tr_idx] - mean\n",
    "    X_train /= std\n",
    "    X_val = X[val_idx] - mean\n",
    "    X_val /= std\n",
    "    X_train = X_train.reshape((X_train.shape[0], 10, 667, 1))\n",
    "    X_val = X_val.reshape((X_val.shape[0], 10, 667, 1))\n",
    "    model.fit(X_train,y[tr_idx], epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    #final_preds[:, i] = model.predict_proba(np.reshape(X_test,(X_test.shape[0],6670,1)))[:, 0]\n",
    "    fold_preds = model.predict_proba(X_val)[:, 0]\n",
    "    print('Fold: {0}, score: {1}'.format(i, roc_auc_score(y[val_idx], fold_preds)))\n",
    "    scores.append(roc_auc_score(y[val_idx], fold_preds))\n",
    "    del model\n",
    "    gc.collect()\n",
    "    i += 1\n",
    "print('Mean (std): {0}({1})'.format(np.mean(scores),np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee1ffa5",
   "metadata": {},
   "source": [
    "### Normalization-L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e5f5d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2af405e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_lstm_l2():\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)),\n",
    "    input_shape=(None,667,1)))\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))))\n",
    "    model.add(TimeDistributed(Dropout(0.5)))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(100, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation= 'sigmoid', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01) ))\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy',Precision(),Recall(),AUC()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd7af4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f81e3b60f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold: 0, score: 0.5584239130434783\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f81e3a17a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold: 1, score: 0.6595441595441596\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f81e388d378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold: 2, score: 0.601295097132285\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f81e381be18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold: 3, score: 0.6433209647495363\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f81e36f5840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold: 4, score: 0.6766409266409267\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f81e3450268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold: 5, score: 0.6374296435272045\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f81e339dbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold: 6, score: 0.7032407407407407\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f81e3210620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold: 7, score: 0.7199074074074074\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f81e315eea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold: 8, score: 0.6203703703703703\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f81e301a9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Fold: 9, score: 0.5509259259259259\n",
      "Mean (std): 0.6371099149082035(0.0533998753247405)\n"
     ]
    }
   ],
   "source": [
    "final_preds = np.zeros((X_test.shape[0], N_SPLITS))\n",
    "i = 0\n",
    "scores = []\n",
    "epochs,batch_size,verbose=50,128,0\n",
    "for tr_idx, val_idx in kf.split(X):\n",
    "    model = cnn_lstm_l2()\n",
    "    mean = X[tr_idx].mean(axis=0)\n",
    "    std = X[tr_idx].std(axis=0)\n",
    "    X_train =  X[tr_idx] - mean\n",
    "    X_train /= std\n",
    "    X_val = X[val_idx] - mean\n",
    "    X_val /= std\n",
    "    X_train = X_train.reshape((X_train.shape[0], 10, 667, 1))\n",
    "    X_val = X_val.reshape((X_val.shape[0], 10, 667, 1))\n",
    "    model.fit(X_train,y[tr_idx], epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    #final_preds[:, i] = model.predict_proba(np.reshape(X_test,(X_test.shape[0],6670,1)))[:, 0]\n",
    "    fold_preds = model.predict_proba(X_val)[:, 0]\n",
    "    print('Fold: {0}, score: {1}'.format(i, roc_auc_score(y[val_idx], fold_preds)))\n",
    "    scores.append(roc_auc_score(y[val_idx], fold_preds))\n",
    "    del model\n",
    "    gc.collect()\n",
    "    i += 1\n",
    "print('Mean (std): {0}({1})'.format(np.mean(scores),np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fea0c3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
